{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller 01 - Analítica de datos\n",
    "- **Autor:** David Santiago Barreto Mora\n",
    "- **Profesor:** Jhon Corredor\n",
    "- **Objetivo:** Conocer las diferentes herramientas para el tratamiento de texto.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga de fuente de datos\n",
    "### 2.b Escribir en secciones de texto del cuaderno python, brevemente la utilidad de las siguientes bibliotecas en azul:\n",
    "a. **numpy:** Biblioteca indispensable para los cálculos numéricos en Python. Su función principal es proporcionar soporte para trabajar con matrices y arrays multidimensionales de gran tamaño, acompañado de un completo conjunto de funciones matemáticas que operan eficientemente sobre estos arrays. La estructura de datos principal de NumPy es ndarray, que permite manipular datos y realizar operaciones matemáticas de forma eficiente. Es crucial para las operaciones de álgebra lineal y el análisis estadístico. Además, NumPy se integra a la perfección con otras bibliotecas populares como Pandas para la manipulación de datos y Matplotlib para la visualización de datos, por lo que es una piedra angular de los flujos de trabajo de la ciencia de datos.\n",
    "\n",
    "b. **regex:** Permite a los usuarios definir y buscar patrones específicos dentro de cadenas o datos de texto, a través de las expresiones regulares (RegEx). Las expresiones regulares consisten en una secuencia de caracteres que definen un patrón de búsqueda.\n",
    "\n",
    "c. **string:** Módulo estándar que proporciona una colección de constantes y funciones diseñadas para facilitar la manipulación de cadenas. Este módulo incluye constantes como string.ascii_letters, string.digits y string.punctuation que simplifican las operaciones relacionadas con caracteres. Además, ofrece varias funciones para trabajar con cadenas de manera eficiente.\n",
    "\n",
    "d. **nltk.tokenize import word_tokenize:** La función word_tokenize forma parte del Natural Language Toolkit (NLTK), una biblioteca para tareas de procesamiento del lenguaje natural (NLP). En concreto, word_tokenize sirve para tokenizar texto, lo que implica dividir el texto en palabras individuales o tokens. La tokenización es un paso fundamental en la NLP y el análisis de textos.\n",
    "\n",
    "Word_tokenize es crucial para preparar datos de texto para diversas tareas de NLP. Desempeña un papel importante en tareas como el análisis de sentimientos, la clasificación de textos y el modelado del lenguaje, ya que descompone el texto en las palabras que lo componen, lo que permite su posterior análisis y la extracción de características.\n",
    "\n",
    "e. **nltk.stem import WordNetLemmatizer:** WordNetLemmatizer es otro componente esencial de la biblioteca NLTK, que se utiliza principalmente para la lematización, un proceso cuyo objetivo es reducir las palabras a su forma básica o de diccionario, conocida como lemas. La lematización es una técnica de preprocesamiento de textos que normaliza las palabras a su forma más básica y significativa.\n",
    "\n",
    "f. **wordcloud import WordCloud:** La biblioteca WordCloud permite generar nubes de palabras, que son representaciones visuales de las palabras más frecuentes en un corpus de texto determinado. En una nube de palabras, las palabras se muestran con distintos tamaños en función de su frecuencia de aparición, lo que facilita la identificación de los términos más destacados.\n",
    "\n",
    "g. **sklearn.feature_extraction.text import TfidfVectorizer:** Componente especializado en la extracción de características de texto. Transforma una colección de documentos de texto en vectores de características numéricas utilizando el método TF-IDF (Term Frequency-Inverse Document Frequency). TF-IDF asigna valores numéricos a las palabras en función de su importancia dentro de cada documento y en todo el corpus.\n",
    "\n",
    "En ciencia de datos, TfidfVectorizer es usado frecuentemente para preparar datos para algoritmos de machine learning. Al cuantificar la importancia de las palabras, mejora el rendimiento de los modelos basados en texto, incluidos los clasificadores y los algoritmos de agrupación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.c Importar al cuaderno las bibliotecas anteriores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mencionamos todas las librerias y modulos mencionados antermiente. Adicionalmente, importamos las librerias frecuentemente usadas, y de vital importancia para el análisis y visualizacion de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wordcloud in c:\\users\\david barreto\\appdata\\roaming\\python\\python39\\site-packages (1.9.2)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (3.5.2)\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (9.2.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previously mentioned libraries are imported.\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import WordCloud\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Additional libraries used for data analysis and visualization\n",
    "# Data anaylisis\n",
    "import pandas as pd\n",
    "\n",
    "# Data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.D. Cargar desde el ENLACE , a objetos dataframe cada uno de los ficheros csv, ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El link contiene un total de 9 dataframes, por lo que crearemos un total de 9 dataframes. Como nota adicional, se crean los dataframes con los archivos descargados debido al tamaño de los .csv. Si se hiciera con los links de internet, los re-runs del codigo se demorarian considerablemente más.\n",
    "\n",
    "Los .csv estan incluidos con el codigo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All dataframes are created from the \"./csvs/\" directory\n",
    "biologia_df = pd.read_csv(\"csvs/Biologia.csv\")\n",
    "bricolage_df = pd.read_csv(\"csvs/Bricolage.csv\")\n",
    "cocina_df = pd.read_csv(\"csvs/Cocina.csv\")\n",
    "criptografia_df = pd.read_csv(\"csvs/Criptografia.csv\")\n",
    "fisica0_df = pd.read_csv(\"csvs/Fisica0.csv\")\n",
    "fisica1_df = pd.read_csv(\"csvs/Fisica1.csv\")\n",
    "fisica2_df = pd.read_csv(\"csvs/Fisica2.csv\")\n",
    "robotica_df = pd.read_csv(\"csvs/Robotica.csv\")\n",
    "viajes_df = pd.read_csv(\"csvs/Viajes.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora miramos la primera fila de cada dataframe para verificar que todos hayan sido creados correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the criticality of the ribosome bindin...</td>\n",
       "      <td>&lt;p&gt;In prokaryotic translation, how critical fo...</td>\n",
       "      <td>ribosome binding-sites translation synthetic-b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  What is the criticality of the ribosome bindin...   \n",
       "\n",
       "                                             content  \\\n",
       "0  <p>In prokaryotic translation, how critical fo...   \n",
       "\n",
       "                                                tags  \n",
       "0  ribosome binding-sites translation synthetic-b...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biologia_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>How do I install a new, non load bearing wall ...</td>\n",
       "      <td>&lt;p&gt;I'm looking to finish my basement and simpl...</td>\n",
       "      <td>remodeling basement carpentry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  How do I install a new, non load bearing wall ...   \n",
       "\n",
       "                                             content  \\\n",
       "0  <p>I'm looking to finish my basement and simpl...   \n",
       "\n",
       "                            tags  \n",
       "0  remodeling basement carpentry  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bricolage_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>How can I get chewy chocolate chip cookies?</td>\n",
       "      <td>&lt;p&gt;My chocolate chips cookies are always too c...</td>\n",
       "      <td>baking cookies texture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                        title  \\\n",
       "0   1  How can I get chewy chocolate chip cookies?   \n",
       "\n",
       "                                             content                    tags  \n",
       "0  <p>My chocolate chips cookies are always too c...  baking cookies texture  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cocina_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>What are the benefits of the two permutation t...</td>\n",
       "      <td>&lt;p&gt;Why do we use a permutation table in the fi...</td>\n",
       "      <td>block-cipher des permutation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   3  What are the benefits of the two permutation t...   \n",
       "\n",
       "                                             content  \\\n",
       "0  <p>Why do we use a permutation table in the fi...   \n",
       "\n",
       "                           tags  \n",
       "0  block-cipher des permutation  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criptografia_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What is spin as it relates to subatomic partic...</td>\n",
       "      <td>&lt;p&gt;I often hear about subatomic particles havi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  What is spin as it relates to subatomic partic...   \n",
       "\n",
       "                                             content  \n",
       "0  <p>I often hear about subatomic particles havi...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fisica0_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94481</td>\n",
       "      <td>Does Super Mario physics work in reality?</td>\n",
       "      <td>&lt;p&gt;This illustration summarizes my question:&lt;/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                      title  \\\n",
       "0  94481  Does Super Mario physics work in reality?   \n",
       "\n",
       "                                             content  \n",
       "0  <p>This illustration summarizes my question:</...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fisica1_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>187184</td>\n",
       "      <td>Can an object have 0 acceleration because its ...</td>\n",
       "      <td>&lt;p&gt;If  an object has an instantaneous velocity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              title  \\\n",
       "0  187184  Can an object have 0 acceleration because its ...   \n",
       "\n",
       "                                             content  \n",
       "0  <p>If  an object has an instantaneous velocity...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fisica2_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the right approach to write the spin c...</td>\n",
       "      <td>&lt;p&gt;Imagine programming a 3 wheel soccer robot....</td>\n",
       "      <td>soccer control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  What is the right approach to write the spin c...   \n",
       "\n",
       "                                             content            tags  \n",
       "0  <p>Imagine programming a 3 wheel soccer robot....  soccer control  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robotica_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What are some Caribbean cruises for October?</td>\n",
       "      <td>&lt;p&gt;My fiancée and I are looking for a good Car...</td>\n",
       "      <td>caribbean cruising vacations</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                         title  \\\n",
       "0   1  What are some Caribbean cruises for October?   \n",
       "\n",
       "                                             content  \\\n",
       "0  <p>My fiancée and I are looking for a good Car...   \n",
       "\n",
       "                           tags  \n",
       "0  caribbean cruising vacations  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viajes_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.e Unir los dataframe de fisica en un solo dataframe\n",
    "Usamos la funcion 'concat' de padas para unir los 3 dataframes (funcion usada en el taller pasado)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisica_total_df = pd.concat([fisica0_df, fisica1_df, fisica2_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.F Crear un diccionario con todos los objetos dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the right approach to write the spin c...</td>\n",
       "      <td>&lt;p&gt;Imagine programming a 3 wheel soccer robot....</td>\n",
       "      <td>soccer control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>How can I modify a low cost hobby servo to run...</td>\n",
       "      <td>&lt;p&gt;I've got some hobby servos (&lt;a href=\"http:/...</td>\n",
       "      <td>control rcservo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>What useful gaits exist for a six legged robot...</td>\n",
       "      <td>&lt;p&gt;&lt;a href=\"http://www.oricomtech.com/projects...</td>\n",
       "      <td>gait walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Good Microcontrollers/SOCs for a Robotics Project</td>\n",
       "      <td>&lt;p&gt;I am looking for a starting point for my pr...</td>\n",
       "      <td>microcontroller arduino raspberry-pi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Nearest-neighbor data structure for non-Euclid...</td>\n",
       "      <td>&lt;p&gt;I'm trying to implement a nearest-neighbor ...</td>\n",
       "      <td>motion-planning rrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>10568</td>\n",
       "      <td>What types of actuators do these industrial bo...</td>\n",
       "      <td>&lt;p&gt;I have a particular example robot that inte...</td>\n",
       "      <td>motor robotic-arm actuator torque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>10573</td>\n",
       "      <td>Technique to increase POV resolution</td>\n",
       "      <td>&lt;p&gt;I have thought of a technique to increase t...</td>\n",
       "      <td>microcontroller electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>10580</td>\n",
       "      <td>How can I upload sketches to an Arduino over a...</td>\n",
       "      <td>&lt;p&gt;I am doing robotics project on Raspberry pi...</td>\n",
       "      <td>arduino raspberry-pi embedded-systems first-ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>10581</td>\n",
       "      <td>EKF SLAM 2d laser scanned datasets usage</td>\n",
       "      <td>&lt;p&gt;How to understand the 2d laser scanner scan...</td>\n",
       "      <td>slam ekf first-robotics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>10584</td>\n",
       "      <td>Communication in SWARM robotics</td>\n",
       "      <td>&lt;p&gt;Hey so I am trying to research into SWARM r...</td>\n",
       "      <td>wireless</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2771 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "0         1  What is the right approach to write the spin c...   \n",
       "1         2  How can I modify a low cost hobby servo to run...   \n",
       "2         3  What useful gaits exist for a six legged robot...   \n",
       "3         4  Good Microcontrollers/SOCs for a Robotics Project   \n",
       "4         5  Nearest-neighbor data structure for non-Euclid...   \n",
       "...     ...                                                ...   \n",
       "2766  10568  What types of actuators do these industrial bo...   \n",
       "2767  10573               Technique to increase POV resolution   \n",
       "2768  10580  How can I upload sketches to an Arduino over a...   \n",
       "2769  10581           EKF SLAM 2d laser scanned datasets usage   \n",
       "2770  10584                    Communication in SWARM robotics   \n",
       "\n",
       "                                                content  \\\n",
       "0     <p>Imagine programming a 3 wheel soccer robot....   \n",
       "1     <p>I've got some hobby servos (<a href=\"http:/...   \n",
       "2     <p><a href=\"http://www.oricomtech.com/projects...   \n",
       "3     <p>I am looking for a starting point for my pr...   \n",
       "4     <p>I'm trying to implement a nearest-neighbor ...   \n",
       "...                                                 ...   \n",
       "2766  <p>I have a particular example robot that inte...   \n",
       "2767  <p>I have thought of a technique to increase t...   \n",
       "2768  <p>I am doing robotics project on Raspberry pi...   \n",
       "2769  <p>How to understand the 2d laser scanner scan...   \n",
       "2770  <p>Hey so I am trying to research into SWARM r...   \n",
       "\n",
       "                                                   tags  \n",
       "0                                        soccer control  \n",
       "1                                       control rcservo  \n",
       "2                                             gait walk  \n",
       "3                  microcontroller arduino raspberry-pi  \n",
       "4                                   motion-planning rrt  \n",
       "...                                                 ...  \n",
       "2766                  motor robotic-arm actuator torque  \n",
       "2767                        microcontroller electronics  \n",
       "2768  arduino raspberry-pi embedded-systems first-ro...  \n",
       "2769                            slam ekf first-robotics  \n",
       "2770                                           wireless  \n",
       "\n",
       "[2771 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dicc = {'biologia': biologia_df, 'bricolage': bricolage_df, 'cocina': cocina_df, \"criptografia\": criptografia_df, \"fisica\": fisica_total_df, \n",
    "           \"robotica\": robotica_df, \"viajes\": viajes_df}\n",
    "df_dicc['robotica']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.g Escribir brevemente en una sección de Texto del Cuaderno python que hace y como se importan al cuaderno python, las siguientes bibliotecas de nltk:\n",
    "a. **stopwords:** Las stopwords son palabras de uso frecuente en un idioma, como \"el\", \"y\", \"en\", \"es\" e \"it\", que tienen poco significado semántico y a menudo se eliminan durante el preprocesamiento del texto en tareas de procesamiento del lenguaje natural (PLN) y minería de textos. NLTK ofrece una lista predefinida de palabras clave para varios idiomas, lo que facilita a los científicos de datos la eliminación de estas palabras de los datos de texto. Este paso es crucial, ya que ayuda a centrarse en las palabras más significativas del texto, reduciendo el ruido en los modelos de NLP y machine learning al descartar palabras que no contribuyen sustancialmente al análisis.\n",
    "\n",
    "b. **punkt:** Ccomponente de NLTK que representa el tokenizador Punkt, un modelo de machine learning no supervisado entrenado para la tokenización de frases. La tokenización de frases consiste en descomponer el texto en frases individuales de forma precisa. Punkt puede manejar varias estructuras de frases e idiomas. Viene pre-entrenado en un amplio corpus de texto, por lo que es capaz de segmentar con precisión el texto en oraciones, lo cual es esencial para numerosas tareas de PLN, incluyendo el resumen de texto, análisis de sentimiento, y el modelado del lenguaje.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.h Importar la biblioteca stopwords de nltk: nltk.download(‘stopwords’), nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting stopwords\n",
      "  Downloading stopwords-1.0.0-py2.py3-none-any.whl (37 kB)\n",
      "Installing collected packages: stopwords\n",
      "Successfully installed stopwords-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download(['stopwords', 'punkt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Pre procesamiento de datos de texto\n",
    "### 3.a Limpieza de datos de texto, usar la función limpieza (fichero funciones.py) para la limpieza de columna content de cada diccionario (identificar y explicar brevemente que elementos esta retirando del texto con la función):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpieza(objeto_df):\n",
    "    contenido = objeto_df.content\n",
    "    #Convertir textos a caracteres en minúsculas\n",
    "    contenido = contenido.apply(lambda x: x.lower())\n",
    "    #Remover HTML tags\n",
    "    contenido = contenido.apply(lambda x: re.sub(r'\\<[^<>]*\\>','',x))\n",
    "    #Remover cualquier caracter que no coincida con una letra, un digito o un guion bajo \"_\" \n",
    "    contenido = contenido.apply(lambda x: re.sub(r'^\\W+|\\W+$',' ',x))\n",
    "    #Remover espacios, nueva linea, tabulador\n",
    "    contenido = contenido.apply(lambda x: re.sub(r'\\s',' ',x))\n",
    "    #Remover puntuacion\n",
    "    contenido = contenido.apply(lambda x: re.sub(r'[^a-zA-Z0-9]',' ',x))\n",
    "    #Tokenizar los data (https://datapeaker.com/big-data/que-es-la-tokenizacion-metodos-para-realizar-la-tokenizacion/)\n",
    "    contenido = contenido.apply(lambda x: word_tokenize(x))\n",
    "    #Remover stopwords\n",
    "    contenido = contenido.apply(lambda x: [i for i in x if i not in stops])\n",
    "    return(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_dicc:\n",
    "    df_dicc[df]['content'] = limpieza(df_dicc[df]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- x.lower(): Convierte todo el texto a minúsculas, garantizando la coherencia de las mayúsculas.\n",
    "\n",
    "- re.sub(r'\\<[^<>]*\\>', '', x): Elimina las etiquetas HTML del texto mediante una expresión regular, eliminando así cualquier marca HTML.\n",
    "\n",
    "- re.sub(r'^\\W+|\\W+$', ' ', x): Elimina todos los caracteres que no sean letras, dígitos o guiones bajos del principio o el final de cada palabra y los \n",
    "sustituye por un espacio.\n",
    "\n",
    "- re.sub(r'\\s', ' ', x): Sustituye los espacios, caracteres de nueva línea y caracteres de tabulación por espacios simples, garantizando un espaciado uniforme.\n",
    "\n",
    "- re.sub(r'[^a-zA-Z0-9]', ' ', x): Elimina los signos de puntuación y los caracteres no alfanuméricos, sustituyéndolos por espacios.\n",
    "word_tokenize(x): Tokeniza el texto, dividiéndolo en palabras individuales o tokens utilizando la función word_tokenize de NLTK.\n",
    "\n",
    "- [i for i in x if i not in stops]: Elimina las palabras de parada (palabras de uso común pero menos informativas) del texto tokenizado filtrando las palabras que se encuentran en las paradas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.b Usar la función limpieza (fichero funciones.py) para la limpieza de columna title de cada diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_dicc:\n",
    "    df_dicc[df]['title'] = limpieza(df_dicc[df]['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.c Crear nubes de puntos a los seis (menos fisT) datos de texto del diccionario usando las rutinas a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_viaje = ''\n",
    "for x in dicc_df['viajes'].title:\n",
    "    for y in x:\n",
    "        tex_viaje +=''+y\n",
    "plt.figure(figsize=(valor, valor)) \n",
    "nubeV = WordCloud(max_words=valor).generate(tx_viaje)\n",
    "plt.imshow(nubeV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.d Combinar en el dataframe fisT las diferentes variantes de palabras, en una única palabra madre que transmita el mismo significado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion = WordNetLemmatizer()\n",
    "dicc['fisT'].title = dicc['test'].title.apply(lambda x:[wordnet.lemmatize(i, pos='v') for i in x])\n",
    "dicc['fisT'].content = dicc['test'].content.apply(lambda x:[wordnet.lemmatize(i, pos='v') for i in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.f Utilizar el concepto de frecuencia de términos y frecuencia inversa de documentos para eliminar todos los tokens no secuenciales de la vectorización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_tokenizer(texto):\n",
    " return texto\n",
    "vector = TfidfVectorizer(tokenizer = identity_tokenizer, lowercase = False)\n",
    "x = vector.fit_transform(diccionario['fisica'].title.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
